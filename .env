# LLM Provider (choose one: openai, ollama, local, anthropic, google)
AQUILA_LLM_PROVIDER=ollama

# OpenAI Configuration
OPENAI_API_KEY=your_key_here

# Ollama / Local Configuration
# Default for Ollama: http://localhost:11434/api
# Default for Local (LM Studio): http://localhost:1234/v1
AQUILA_API_BASE=http://localhost:11434/api

# Agent Configuration
AQUILA_MODEL=llama3
AQUILA_TEMPERATURE=0.3

# Language Settings
AQUILA_DEFAULT_LANGUAGE=auto

# Methodology
AQUILA_METHODOLOGY=auto

# Memory Settings
AQUILA_MEMORY_ENABLED=true
AQUILA_PROJECT_MEMORY=true

# Tool Settings
AQUILA_MAX_SOURCES=50

# Debug Settings
AQUILA_DEBUG=false
AQUILA_LOG_LEVEL=INFO
